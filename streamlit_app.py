# -*- coding: utf-8 -*-
"""열처리 예지보전 AI 데이터셋.ipynb의 사본

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RbDWMXLaFg67TWTB5R33skIWFoLnVOql
"""

import shutil

shutil.unpack_archive('/content/Dataset_열처리 예지보전 AI 데이터셋.zip', '/content/')

import pandas as pd
import numpy as np

df = pd.read_csv('/content/data/data.csv', encoding='cp949')
print(df.head())

import warnings
warnings.filterwarnings(action='ignore')

df['TAG_MIN'] =pd.to_datetime(df.TAG_MIN, format='%Y-%m-%d %H:%M:%S')

import plotly.express as px

# '소입로 온도 1 Zone' 데이터를 사용하여 라인 차트 그리기
fig = px.line(df, y='소입로 온도 1 Zone', title='소입로 온도 1 Zone Temperature Over Index')

# x축과 y축 라벨 설정
fig.update_layout(
    xaxis_title="Index",
    yaxis_title="Temperature",
)

# 그래프 출력
fig.show()

df.isnull().sum()

df = df.fillna(df.mean())

for col in df.columns:
    print( col,':', len(df[col].value_counts()))

import plotly.express as px
import plotly.graph_objects as go
import pandas as pd

# 필요한 데이터프레임을 가정
# target_cor에 대한 상관관계 계산 부분 유지
target_cor = df.corr().loc[['건조 1존 OP', '건조 2존 OP', '건조로 온도 1 Zone',
                            '건조로 온도 2 Zone', '세정기', '소입1존 OP', '소입2존 OP', '소입3존 OP', '소입4존 OP',
                            '소입로 CP 값', '소입로 CP 모니터 값', '소입로 온도 1 Zone', '소입로 온도 2 Zone',
                            '소입로 온도 3 Zone', '소입로 온도 4 Zone', '솔트 1존 OP', '솔트 2존 OP',
                            '솔트 슬러지 제거', '솔트 컨베이어 온도 1 Zone', '솔트 컨베이어 온도 2 Zone',
                            '솔트조 온도 1 Zone', '솔트조 온도 2 Zone']]

# 상관관계 히트맵 그리기
fig = px.imshow(target_cor,
                labels=dict(color="Correlation"),
                x=target_cor.columns,
                y=target_cor.index,
                color_continuous_scale='RdBu_r',
                zmin=-1, zmax=1)

# 히트맵에 수치 값 표시 추가
fig.update_traces(text=target_cor.values, texttemplate="%{text:.2f}", textfont_size=12)

# 레이아웃 업데이트 (그래프 크기, 제목 등 설정)
fig.update_layout(
    title="Correlation Heatmap",
    xaxis_title="Features",
    yaxis_title="Features",
    width=1000,  # 그래프의 너비 조정
    height=800   # 그래프의 높이 조정
)

# 그래프 출력
fig.show()

# 이상치 개수를 기록할 열 추가
df['이상치개수'] = 0

# 각 열에 대해 이상치 탐지
for col in df.columns:
    # 사분위수 계산
    thirdq, firstq = df[col].quantile(0.75), df[col].quantile(0.25)
    interquartilerange = 1.5 * (thirdq - firstq)

    # 이상치 기준 값 계산
    outlierhigh = thirdq + interquartilerange
    outlierlow = firstq - interquartilerange

    # 각 행에 대해 이상치 여부 확인
    for i in df.index:
        if df[col][i] > outlierhigh or df[col][i] < outlierlow:
            df.loc[i, '이상치개수'] += 1

# 결과 출력
df.head()

df['이상치개수'].value_counts()

df['설비 이상신호'] =np.where(df['이상치개수'] < 9, 0, 1)
df['설비 이상신호'].value_counts()

normal = df.loc[df['설비 이상신호'] ==0]
abnormal = df.loc[df['설비 이상신호'] ==1]
print('정상 데이터:', len(normal))
print('설비이상 데이터:', len(abnormal))

normal.drop(columns='이상치개수', inplace=True)
abnormal.drop(columns='이상치개수', inplace=True)

from sklearn.model_selection import train_test_split
train_Y, test_Y = train_test_split(normal, test_size =0.3, random_state =1)
print('학습 데이터셋 개수:', len(train_Y))
print('테스트 데이터셋 개수:', len(test_Y))

from sklearn.preprocessing import MinMaxScaler
import pandas as pd

# MinMaxScaler 객체 생성
scaler = MinMaxScaler()

# 숫자형 데이터만 선택 (datetime 또는 object 타입 제외)
numeric_cols_train = train_Y.select_dtypes(include=[np.number]).columns[:-1]  # 마지막 열(y 값 제외)
numeric_cols_test = test_Y.select_dtypes(include=[np.number]).columns[:-1]
numeric_cols_abnormal = abnormal.select_dtypes(include=[np.number]).columns[:-1]

# 정상 학습 데이터 스케일링
normal_train_scaled = scaler.fit_transform(train_Y[numeric_cols_train])
X_normal_train = pd.DataFrame(data=normal_train_scaled,
                              index=train_Y.index,
                              columns=numeric_cols_train)

# 정상 학습 데이터 y 값 설정
y_normal_train = train_Y.iloc[:, -1]

# 최종 정상 학습 데이터
train_Y_normal = pd.concat([X_normal_train, y_normal_train], axis=1)

# 정상 테스트 데이터 스케일링
normal_test_scaled = scaler.transform(test_Y[numeric_cols_test])
X_normal_test = pd.DataFrame(data=normal_test_scaled,
                             index=test_Y.index,
                             columns=numeric_cols_test)

# 정상 테스트 데이터 y 값 설정
y_normal_test = test_Y.iloc[:, -1]

# 최종 정상 테스트 데이터
test_Y_normal = pd.concat([X_normal_test, y_normal_test], axis=1)

# 비정상 테스트 데이터 스케일링
abnormal_test_scaled = scaler.transform(abnormal[numeric_cols_abnormal])
X_abnormal_test = pd.DataFrame(data=abnormal_test_scaled,
                               index=abnormal.index,
                               columns=numeric_cols_abnormal)

# 비정상 테스트 데이터 y 값 설정
y_abnormal_test = abnormal.iloc[:, -1]

# 최종 비정상 테스트 데이터
abnormal_data = pd.concat([X_abnormal_test, y_abnormal_test], axis=1)

# 필요한 패키지를 불러온다
import tensorflow as tf
tf.random.set_seed(1)
from keras.layers import Dense
from keras.models import Sequential

# 모델 구축
model_encoder = Sequential([
Dense(15, activation="relu"),
Dense(10, activation="relu"),
Dense(5, activation="relu")
])
model_decoder = Sequential([
Dense(10, activation="relu", input_shape=[5]),
Dense(15, activation="relu"),
Dense(X_normal_train.shape[1], activation="relu")
])
AE_model =Sequential([model_encoder, model_decoder])

from tensorflow.keras.optimizers import Adam
AE_model.compile(loss="mse", optimizer=Adam(learning_rate=0.001))

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# 모델 저장 경로 설정 (따옴표 오류 수정)
model_path = '/content/{epoch:02d}-{val_loss:.4f}.keras'

# 콜백 설정
callbacks = [
    EarlyStopping(monitor="val_loss", patience=10, mode="min"),
    ModelCheckpoint(filepath=model_path, monitor="val_loss", save_best_only=True, mode="min")
]

# 모델 학습
history = AE_model.fit(
    X_normal_train, X_normal_train,  # Autoencoder라서 입력과 출력이 동일
    batch_size=32,
    epochs=100,
    validation_split=0.2,
    callbacks=callbacks
)

import plotly.graph_objects as go

# Plotly 그래프 생성
fig = go.Figure()

# Training loss 추가
fig.add_trace(go.Scatter(x=list(range(len(history.history['loss']))),
                         y=history.history['loss'],
                         mode='lines',
                         name='Training Loss'))

# Validation loss 추가
fig.add_trace(go.Scatter(x=list(range(len(history.history['val_loss']))),
                         y=history.history['val_loss'],
                         mode='lines',
                         name='Validation Loss'))

# 레이아웃 업데이트
fig.update_layout(
    title='Training and Validation Loss',
    xaxis_title='Epochs',
    yaxis_title='Loss',
    width=800,
    height=400
)

# 그래프 출력
fig.show()

# plt.rcParams['font.size'] =13
# plt.figure(figsize=(10,5))
# plt.plot(history.history['loss'], label='Training loss')
# plt.plot(history.history['val_loss'], label='Validation Loss')
# plt.legend()
# plt.show()

def score(model,X):
    scores_ = np.square((X.values-model.predict(X))).mean(axis=1)
    return scores_

ae_train = score(AE_model, X_normal_train)
ae_test = score(AE_model, X_normal_test)

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# 두 개의 서브플롯 생성 (행 2, 열 1)
fig = make_subplots(rows=2, cols=1, subplot_titles=("Train Data", "Test Data"))

# Train 데이터 히스토그램 및 KDE 추가
fig.add_trace(
    go.Histogram(x=ae_train, nbinsx=100, name='Train', marker_color='blue', opacity=0.7),
    row=1, col=1
)
fig.add_trace(
    go.Scatter(x=sorted(ae_train), y=[0.01]*len(ae_train), mode='lines', line=dict(color='blue'), showlegend=False), # 대략적 KDE 표현
    row=1, col=1
)

# Test 데이터 히스토그램 및 KDE 추가
fig.add_trace(
    go.Histogram(x=ae_test, nbinsx=100, name='Test', marker_color='red', opacity=0.7),
    row=2, col=1
)
fig.add_trace(
    go.Scatter(x=sorted(ae_test), y=[0.01]*len(ae_test), mode='lines', line=dict(color='red'), showlegend=False), # 대략적 KDE 표현
    row=2, col=1
)

# 그래프 레이아웃 조정
fig.update_layout(
    height=800,  # 그래프 높이
    width=1000,  # 그래프 너비
    title_text="Train vs Test Data Distribution",
    showlegend=False
)

# 그래프 출력
fig.show()

# 임계값은 0.03로 함
merged_data = pd.concat([X_normal_train, X_normal_test])
ae_scores = pd.DataFrame(index=merged_data.index)
ae_scores['score'] = list(np.hstack([ae_train, ae_test]))
# 설정한 임계값 보다 큰 경우 비정상
ae_scores['anomaly'] =0.03 < ae_scores['score']
ae_scores.head()

ae_scores['anomaly'].value_counts()

import plotly.graph_objects as go
import numpy as np

# Plotly 그래프 생성
fig = go.Figure()

# 히스토그램 추가 (정상 테스트 데이터)
fig.add_trace(go.Histogram(x=ae_test, nbinsx=50, name='Test MSE Loss', marker_color='blue'))

# 기준선 추가 (0.03 임계값 기준으로 이상치 판단)
fig.add_trace(go.Scatter(
    x=[0.03, 0.03],  # x 좌표 (기준선의 위치)
    y=[0, 1],  # y 좌표 (y축 범위, 이후 자동으로 업데이트됨)
    mode="lines",
    line=go.scatter.Line(color="red", dash="dash"),
    name="Threshold (0.03)"
))

# 레이아웃 업데이트
fig.update_layout(
    title="Test MSE Loss Distribution with Threshold",
    xaxis_title="Test MSE Loss",
    yaxis_title="No of Samples",
    showlegend=True,
    height=600,
    width=800
)

# 그래프 출력
fig.show()

# 임계치 기준으로 불량 데이터의 개수 계산
test_Y_normal = ae_test > 0.03
print("test 데이터의 불량예측 개수: ", np.sum(test_Y_normal))

abnormal_df =abnormal_data.copy()
# 불필요한 변수 삭제
abnormal_df = abnormal_df.drop(['설비 이상신호'], axis=1)
# 모두 비정상 값 복원오차 값 도출
ae_abnormal = score(AE_model, abnormal_df)

import plotly.graph_objects as go
import numpy as np

# 히스토그램을 그릴 데이터 (ae_abnormal)
fig = go.Figure()

# 히스토그램 추가
fig.add_trace(go.Histogram(x=ae_abnormal, nbinsx=50, name='Abnormal Data', marker_color='blue'))

# 기준선 추가 (MSE Loss 기준으로 이상치 판단)
fig.add_trace(go.Scatter(
    x=[0.03, 0.03],  # x 좌표 (기준선의 위치)
    y=[0, 1],  # y 좌표 (y축 범위, 이후 업데이트됨)
    mode="lines",
    line=go.scatter.Line(color="red", dash="dash"),
    name="Threshold (0.03)"
))

# 레이아웃 업데이트
fig.update_layout(
    title="Histogram of Test MSE Loss with Abnormal Threshold",
    xaxis_title="Test MSE Loss",
    yaxis_title="No of Samples",
    showlegend=True,
    height=600,
    width=800
)

# 그래프 출력
fig.show()

# 이상점으로 판단한 데이터 확인
test_N_abnormal = ae_abnormal > 0.03
print("이상점으로 예측한 개수: ", np.sum(test_N_abnormal))

# # 모두 비정상인 값 예측
# # 시각화
# plt.figure(figsize=(8,6))
# plt.hist(ae_abnormal, bins=50)
# plt.xlabel("test MSE loss")
# plt.ylabel("No of samples")
# plt.axvline(0.03, color='red', linestyle='--', linewidth=1)
# plt.show()
# # 이상점으로 판단한 데이터 확인
# test_N_abnormal = ae_abnormal >0.03
# print("이상점으로 예측한 개수: ", np.sum(test_N_abnormal))

from sklearn.metrics import confusion_matrix
# 결과 값을 통한 정량적 지표 확인
# 실제 양품 불량으로 결합
true = np.concatenate([np.zeros(len(y_normal_test)), np.ones(len(abnormal_data))])
# 예측한 양품, 불량으로 결합
prediction = np.concatenate([test_Y_normal, test_N_abnormal])
# 혼동 행렬
confusion_matrix(true, prediction)

import plotly.express as px
import plotly.graph_objects as go
from sklearn.metrics import confusion_matrix
import numpy as np

# 혼동 행렬 계산
cm = confusion_matrix(true, prediction)

# 클래스 이름
class_names = ['정상', '비정상']

# Plotly에서 혼동 행렬을 히트맵으로 시각화
fig = px.imshow(cm,
                labels=dict(x="Predicted label", y="True label", color="Count"),
                x=class_names,
                y=class_names,
                text_auto=True,  # 각 셀에 값을 자동으로 표시
                color_continuous_scale='Blues')

# 레이아웃 업데이트
fig.update_layout(
    title="Confusion Matrix",
    width=500,
    height=400
)

# 그래프 출력
fig.show()

from sklearn.metrics import classification_report
print(classification_report(true, prediction, target_names=['normal', 'abnormal']))
